project: rtirca
name: train_rtirca_n
task: detect
mode: train
model: rtirca_n.pt
teacher: pretrained_rtirca_l.pt # (str) path to teacher pretrained model file
pretrained: True # True by default
device: [-1]
seed: 42
deterministic: True
amp: False
# patience: 200
data: ISED.yaml
epochs: 200
batch: 16
optimizer: SGD
lr0: 0.01
momentum: 0.937
weight_decay: 0.0005
alpha: 1e-3 # (float) spatial-channel relevances alignment loss weight
beta: 1e-8 # (float) global feature distillation loss weight
gamma: 1e-6 # (float) mutual information loss weight
temperature: 0.5 # (float) relevance loss regularization temperature
has_rev: True # (bool) whether the knowlage distillation use the relevance loss
has_irca: True # (bool) whether the knowlage distillation use the global feature distillation loss
has_mut: True # (bool) whether the knowlage distillation use the mutual information loss
layer_indices: [14, 17, 20, 23] # (List[int]) List of layer indices for knowledge distillation

# Output channel dimensions for each layer in the student model
# Mapping: layer_index -> number_of_channels
# None indicates non-convolutional layers (e.g., Upsample, Concat, etc.)
student_channels:
  {
    0: 16,
    1: 32,
    2: 64,
    3: 64,
    4: 128,
    5: 128,
    6: 128,
    7: 256,
    8: 256,
    9: 256,
    10: 256,
    11: 260,
    12: None,
    13: None,
    14: 128,
    15: None,
    16: None,
    17: 64,
    18: 64,
    19: None,
    20: 128,
    21: 128,
    22: None,
    23: 256,
    24: None,
  }
# Output channel dimensions for each layer in the teacher model
teacher_channels:
  {
    0: 64,
    1: 128,
    2: 256,
    3: 256,
    4: 512,
    5: 512,
    6: 512,
    7: 512,
    8: 512,
    9: 512,
    10: 512,
    11: 516,
    12: None,
    13: None,
    14: 512,
    15: None,
    16: None,
    17: 256,
    18: 256,
    19: None,
    20: 512,
    21: 512,
    22: None,
    23: 512,
    24: None,
  }
